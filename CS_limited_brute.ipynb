{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9404f2",
   "metadata": {},
   "source": [
    "_Version log: Considers moving n detectors at a time._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddbb7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, itertools, random, math, copy, time\n",
    "import numpy as np\n",
    "import CS_functions as cs\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import fft as spfft\n",
    "\n",
    "plt.rcParams.update({'font.size':16})\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "531375fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# made by Thomas Lux on Stack Overflow\n",
    "# Return a randomized \"range\" using a Linear Congruential Generator\n",
    "# to produce the number sequence. Parameters are the same as for \n",
    "# python builtin \"range\".\n",
    "#   Memory  -- storage for 8 integers, regardless of parameters.\n",
    "#   Compute -- at most 2*\"maximum\" steps required to generate sequence.\n",
    "#\n",
    "def random_range(start, stop=None, step=None):\n",
    "    # Set a default values the same way \"range\" does.\n",
    "    if (stop == None): start, stop = 0, start\n",
    "    if (step == None): step = 1\n",
    "    # Use a mapping to convert a standard range into the desired range.\n",
    "    mapping = lambda i: (i*step) + start\n",
    "    # Compute the number of numbers in this range.\n",
    "    maximum = (stop - start) // step\n",
    "    # Seed range with a random integer.\n",
    "    value = random.randint(0, maximum-1)\n",
    "    # \n",
    "    # Construct an offset, multiplier, and modulus for a linear\n",
    "    # congruential generator. These generators are cyclic and\n",
    "    # non-repeating when they maintain the properties:\n",
    "    # \n",
    "    #   1) \"modulus\" and \"offset\" are relatively prime.\n",
    "    #   2) [\"multiplier\" - 1] is divisible by all prime factors of \"modulus\".\n",
    "    #   3) [\"multiplier\" - 1] is divisible by 4 if \"modulus\" is divisible by 4. #rule three seems a little arbitrary. Why does it matter and are there any other multiples that we need to watch out for?\n",
    "    # \n",
    "    offset = random.randint(0, maximum-1) * 2 + 1      # Pick a random odd-valued offset.\n",
    "    #multiplier = 4*(maximum//4) + 1                 # Pick a multiplier 1 greater than a multiple of 4.\n",
    "    modulus = int(2**math.ceil(math.log2(maximum))) # Pick a modulus just big enough to generate all numbers (power of 2).\n",
    "    # Track how many random numbers have been returned.\n",
    "    found = 0\n",
    "    while found < maximum:\n",
    "        # If this is a valid value, yield it in generator fashion.\n",
    "        if value < maximum:\n",
    "            found += 1\n",
    "            yield mapping(value)\n",
    "        # Calculate the next value in the sequence.\n",
    "        #value = (value*multiplier + offset) % modulus\n",
    "        value = (value +offset) % modulus #removing the multiplier makes it less random but more reliable for extremely large numbers (>1e13)\n",
    "    \n",
    "\n",
    "# made by openai (but debugged by me because robots are not taking over the world anytime soon!)\n",
    "def find_nth_combination(N, r, idx):\n",
    "    num_combinations = math.comb(N, r)\n",
    "    \n",
    "    if num_combinations <= idx :\n",
    "        raise ValueError(\"idx is larger than the total number of combinations\")\n",
    "    \n",
    "    result = []\n",
    "    n = 0\n",
    "    while r > 0:\n",
    "        num_combinations = math.comb(N -n -1, r - 1)\n",
    "        if num_combinations <= idx:\n",
    "            n += 1\n",
    "            idx -= num_combinations\n",
    "        else:\n",
    "            result.append(n)\n",
    "            n += 1\n",
    "            r -= 1\n",
    "        \n",
    "        if r == 0:\n",
    "            return tuple(result)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af9eddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 15\n",
    "file_name = \"1dmockanderrors{:d}\".format(file_number)\n",
    "#file_name = \"240802134128_altered1d\"\n",
    "file_type = \".csv\"\n",
    "\n",
    "optlocs_file = \"data\\\\\" + file_name +\"_optlocs.csv\"\n",
    "target, uncertainties = cs.open_dataset(file_name, file_type)\n",
    "total_points = len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdd8a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ INITIALISE AND RESET BRUTE FORCE ######################\n",
    "\n",
    "reduced_points = 6\n",
    "regularization_coeffient = 1e-3\n",
    "depth = 1 # How many detectors can the algorithm move at once? DO NOT INCREASE THIS TOO MUCH. It has expontial time complexity.\n",
    "max_iterations = 20\n",
    "\n",
    "best_detectors = cs.subsample_1d(total_points, reduced_points, \"regular\")\n",
    "best_score = cs.evaluate_score(best_detectors, target, uncertainties, regularization_coeffient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "859b7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "[0, 40, 80, 119, 159, 199] 9.721031843630236\n",
      "[86, 40, 80, 119, 159, 199] 8.07729114495846\n",
      "[86, 40, 80, 92, 159, 199] 5.036153137404374\n",
      "[86, 40, 80, 92, 159, 128] 3.6207796786464197\n",
      "[86, 67, 80, 92, 159, 128] 2.302831240441394\n",
      "[86, 67, 105, 92, 159, 128] 1.9302855464598552\n",
      "[86, 67, 105, 92, 54, 128] 1.5819109146414745\n",
      "[98, 67, 105, 92, 54, 128] 1.5572202478539086\n",
      "[98, 74, 105, 92, 54, 128] 1.4576787830458964\n",
      "[98, 74, 116, 92, 54, 128] 1.2509235246902781\n",
      "[98, 73, 116, 92, 54, 128] 1.1964725642876342\n",
      "55.04244422912598\n"
     ]
    }
   ],
   "source": [
    "################# LIMITED BRUTE FORCE ###################\n",
    "\n",
    "print(math.comb(reduced_points, depth) *math.comb(total_points, depth))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for n in range(max_iterations):\n",
    "    print(end= \"[\")\n",
    "    print(*best_detectors, sep= \", \", end= \"] \")\n",
    "    print(best_score)\n",
    "    old_detectors = np.copy(best_detectors)\n",
    "\n",
    "    # pick_detectors = (find_nth_combination(reduced_points, depth, random_index) for random_index in random_range(math.comb(reduced_points, depth))) # checking in a random order is useful if you plan on stopping the algorithm early\n",
    "    # pick_detectors = (find_nth_combination(reduced_points, depth, random_index) for random_index in range(math.comb(reduced_points, depth))) # higher values of depth will produce better results at the cost of computation time\n",
    "    pick_detectors = (index for index in range(reduced_points)) # simplest case where only one detector is moved at a time\n",
    "    \n",
    "    for moving_detectors in pick_detectors:\n",
    "\n",
    "        # pick_samples = (find_nth_combination(total_points, depth, random_index) for random_index in range(math.comb(total_points, depth))) # checking in a random order is useful if you plan on stopping the algorithm early\n",
    "        # pick_samples = (find_nth_combination(total_points, depth, random_index) for random_index in range(math.comb(total_points, depth))) # higher values of depth will produce better results at the cost of computation time\n",
    "        pick_samples = (index for index in range(total_points) if index not in old_detectors) # simplest case where only one detector is moved at a time. Now checks for duplicates.\n",
    "        for new_samples in pick_samples:\n",
    "            detectors = np.copy(old_detectors)\n",
    "            detectors[np.array(moving_detectors)] = new_samples\n",
    "\n",
    "            score = cs.evaluate_score(detectors, target, uncertainties, regularization_coeffient)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_detectors = np.copy(detectors)\n",
    "                best_score = np.copy(score)\n",
    "\n",
    "    if np.all([old_detectors == best_detectors]):\n",
    "        break\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)\n",
    "\n",
    "cs.append_array_to_csv(best_detectors, optlocs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d204d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1964725642876342\n"
     ]
    }
   ],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ae092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98,73,116,92,54,128]"
     ]
    }
   ],
   "source": [
    "print(end=\"[\")\n",
    "print(*best_detectors, sep= \",\", end=\"]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
